{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from pcdet.config import cfg, cfg_from_list, cfg_from_yaml_file, log_config_to_file\n",
    "from pcdet.utils import common_utils\n",
    "import torch\n",
    "\n",
    "tv = None\n",
    "try:\n",
    "  import cumm.tensorview as tv\n",
    "except:\n",
    "  pass\n",
    "\n",
    "from nw_models.voxelnext import VoxelNext\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = Path(\"/home/cuda_pp/OpenPCDet/data/nuscenes/v1.0-mini\")\n",
    "\n",
    "info_path = Path(\"/home/cuda_pp/OpenPCDet/data/nuscenes/v1.0-mini/nuscenes_infos_10sweeps_val.pkl\")\n",
    "\n",
    "with open(info_path, 'rb') as f:\n",
    "  infos = pickle.load(f)\n",
    "  info = infos[10]\n",
    "  # pprint(infos[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ego_points(points, center_radius=1.0):\n",
    "  mask = ~((np.abs(points[:, 0]) < center_radius) & (np.abs(points[:, 1]) < center_radius))\n",
    "  return points[mask]\n",
    "\n",
    "def get_sweep(sweep_info):\n",
    "    lidar_path = root_path / sweep_info['lidar_path']\n",
    "    points_sweep = np.fromfile(str(lidar_path), dtype=np.float32, count=-1).reshape([-1, 5])[:, :4]\n",
    "    points_sweep = remove_ego_points(points_sweep).T\n",
    "    if sweep_info['transform_matrix'] is not None:\n",
    "        num_points = points_sweep.shape[1]\n",
    "        points_sweep[:3, :] = sweep_info['transform_matrix'].dot(\n",
    "            np.vstack((points_sweep[:3, :], np.ones(num_points))))[:3, :]\n",
    "\n",
    "    cur_times = sweep_info['time_lag'] * np.ones((1, points_sweep.shape[1]))\n",
    "    return points_sweep.T, cur_times.T\n",
    "\n",
    "def get_lidar_with_sweeps(info, max_sweeps=1):\n",
    "    lidar_path = root_path / info['lidar_path']\n",
    "    points = np.fromfile(str(lidar_path), dtype=np.float32, count=-1).reshape([-1, 5])[:, :4]\n",
    "\n",
    "    sweep_points_list = [points]\n",
    "    sweep_times_list = [np.zeros((points.shape[0], 1))]\n",
    "\n",
    "    for k in np.random.choice(len(info['sweeps']), max_sweeps - 1, replace=False):\n",
    "        points_sweep, times_sweep = get_sweep(info['sweeps'][k])\n",
    "        sweep_points_list.append(points_sweep)\n",
    "        sweep_times_list.append(times_sweep)\n",
    "\n",
    "    points = np.concatenate(sweep_points_list, axis=0)\n",
    "    times = np.concatenate(sweep_times_list, axis=0).astype(points.dtype)\n",
    "\n",
    "    points = np.concatenate((points, times), axis=1)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# DATASET CONFIG ###################\n",
      " {'DATASET': 'NuScenesDataset', 'DATA_PATH': '../data/nuscenes', 'VERSION': 'v1.0-mini', 'MAX_SWEEPS': 10, 'PRED_VELOCITY': True, 'SET_NAN_VELOCITY_TO_ZEROS': True, 'FILTER_MIN_POINTS_IN_GT': 1, 'DATA_SPLIT': {'train': 'train', 'test': 'val'}, 'INFO_PATH': {'train': ['nuscenes_infos_10sweeps_train.pkl'], 'test': ['nuscenes_infos_10sweeps_val.pkl']}, 'POINT_CLOUD_RANGE': [-54.0, -54.0, -5.0, 54.0, 54.0, 3.0], 'BALANCED_RESAMPLING': True, 'DATA_AUGMENTOR': {'DISABLE_AUG_LIST': ['placeholder'], 'AUG_CONFIG_LIST': [{'NAME': 'gt_sampling', 'DB_INFO_PATH': ['nuscenes_dbinfos_10sweeps_withvelo.pkl'], 'USE_SHARED_MEMORY': False, 'DB_DATA_PATH': ['nuscenes_dbinfos_10sweeps_withvelo_global.pkl.npy'], 'PREPARE': {'filter_by_min_points': ['car:5', 'truck:5', 'construction_vehicle:5', 'bus:5', 'trailer:5', 'barrier:5', 'motorcycle:5', 'bicycle:5', 'pedestrian:5', 'traffic_cone:5']}, 'SAMPLE_GROUPS': ['car:2', 'truck:2', 'construction_vehicle:2', 'bus:2', 'trailer:2', 'barrier:2', 'motorcycle:2', 'bicycle:2', 'pedestrian:2', 'traffic_cone:2'], 'NUM_POINT_FEATURES': 5, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': True}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x', 'y']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.9, 1.1]}, {'NAME': 'random_world_translation', 'NOISE_TRANSLATE_STD': [0.5, 0.5, 0.5]}]}, 'POINT_FEATURE_ENCODING': {'encoding_type': 'absolute_coordinates_encoding', 'used_feature_list': ['x', 'y', 'z', 'intensity', 'timestamp'], 'src_feature_list': ['x', 'y', 'z', 'intensity', 'timestamp']}, 'DATA_PROCESSOR': [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': True}}, {'NAME': 'transform_points_to_voxels', 'VOXEL_SIZE': [0.075, 0.075, 0.2], 'MAX_POINTS_PER_VOXEL': 10, 'MAX_NUMBER_OF_VOXELS': {'train': 120000, 'test': 160000}}], '_BASE_CONFIG_': 'cfgs/dataset_configs/nuscenes_dataset.yaml'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cfg_file = \"/home/cuda_pp/OpenPCDet/tools/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext.yaml\"\n",
    "\n",
    "cfg_from_yaml_file(cfg_file, cfg)\n",
    "cfg.TAG = Path(cfg_file).stem\n",
    "cfg.EXP_GROUP_PATH = '/'.join(cfg_file.split('/')[1:-1])  # remove 'cfgs' and 'xxxx.yaml'\n",
    "\n",
    "dataset_cfg = cfg.DATA_CONFIG\n",
    "\n",
    "print(\"############# DATASET CONFIG ###################\\n\", dataset_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = get_lidar_with_sweeps(info, max_sweeps=dataset_cfg.MAX_SWEEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle point indexes\n",
    "# shuffle_idx = np.random.permutation(points.shape[0])\n",
    "# points = points[shuffle_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoxelGeneratorWrapper():\n",
    "  def __init__(\n",
    "          self, vsize_xyz, coors_range_xyz, num_point_features, max_num_points_per_voxel,\n",
    "          max_num_voxels):\n",
    "    try:\n",
    "      from spconv.utils import VoxelGeneratorV2 as VoxelGenerator\n",
    "      self.spconv_ver = 1\n",
    "    except:\n",
    "      try:\n",
    "        from spconv.utils import VoxelGenerator\n",
    "        self.spconv_ver = 1\n",
    "      except:\n",
    "        from spconv.utils import Point2VoxelCPU3d as VoxelGenerator\n",
    "        self.spconv_ver = 2\n",
    "\n",
    "    if self.spconv_ver == 1:\n",
    "      self._voxel_generator = VoxelGenerator(\n",
    "          voxel_size=vsize_xyz,\n",
    "          point_cloud_range=coors_range_xyz,\n",
    "          max_num_points=max_num_points_per_voxel,\n",
    "          max_voxels=max_num_voxels\n",
    "      )\n",
    "    else:\n",
    "      self._voxel_generator = VoxelGenerator(\n",
    "          vsize_xyz=vsize_xyz,\n",
    "          coors_range_xyz=coors_range_xyz,\n",
    "          num_point_features=num_point_features,\n",
    "          max_num_points_per_voxel=max_num_points_per_voxel,\n",
    "          max_num_voxels=max_num_voxels\n",
    "      )\n",
    "\n",
    "  def generate(self, points):\n",
    "    if self.spconv_ver == 1:\n",
    "      voxel_output = self._voxel_generator.generate(points)\n",
    "      if isinstance(voxel_output, dict):\n",
    "        voxels, coordinates, num_points = \\\n",
    "            voxel_output['voxels'], voxel_output['coordinates'], voxel_output['num_points_per_voxel']\n",
    "      else:\n",
    "        voxels, coordinates, num_points = voxel_output\n",
    "    else:\n",
    "      assert tv is not None, f\"Unexpected error, library: 'cumm' wasn't imported properly.\"\n",
    "      voxel_output = self._voxel_generator.point_to_voxel(tv.from_numpy(points))\n",
    "      tv_voxels, tv_coordinates, tv_num_points = voxel_output\n",
    "      # make copy with numpy(), since numpy_view() will disappear as soon as the generator is deleted\n",
    "      voxels = tv_voxels.numpy()\n",
    "      coordinates = tv_coordinates.numpy()\n",
    "      num_points = tv_num_points.numpy()\n",
    "    return voxels, coordinates, num_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointFeatureEncoder(object):\n",
    "    def __init__(self, config, point_cloud_range=None):\n",
    "        super().__init__()\n",
    "        self.point_encoding_config = config\n",
    "        assert list(self.point_encoding_config.src_feature_list[0:3]) == ['x', 'y', 'z']\n",
    "        self.used_feature_list = self.point_encoding_config.used_feature_list\n",
    "        self.src_feature_list = self.point_encoding_config.src_feature_list\n",
    "        self.point_cloud_range = point_cloud_range\n",
    "\n",
    "    @property\n",
    "    def num_point_features(self):\n",
    "        return getattr(self, self.point_encoding_config.encoding_type)(points=None)\n",
    "\n",
    "    def forward(self, points):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dict:\n",
    "                points: (N, 3 + C_in)\n",
    "                ...\n",
    "        Returns:\n",
    "            data_dict:\n",
    "                points: (N, 3 + C_out),\n",
    "                use_lead_xyz: whether to use xyz as point-wise features\n",
    "                ...\n",
    "        \"\"\"\n",
    "        points, use_lead_xyz = getattr(self, self.point_encoding_config.encoding_type)(\n",
    "            points\n",
    "        )\n",
    "       \n",
    "        if self.point_encoding_config.get('filter_sweeps', False) and 'timestamp' in self.src_feature_list:\n",
    "            max_sweeps = self.point_encoding_config.max_sweeps\n",
    "            idx = self.src_feature_list.index('timestamp')\n",
    "            dt = np.round(points[:, idx], 2)\n",
    "            max_dt = sorted(np.unique(dt))[min(len(np.unique(dt))-1, max_sweeps-1)]\n",
    "            points = points[dt <= max_dt]\n",
    "        \n",
    "        return points, use_lead_xyz\n",
    "\n",
    "    def absolute_coordinates_encoding(self, points=None):\n",
    "        if points is None:\n",
    "            num_output_features = len(self.used_feature_list)\n",
    "            return num_output_features\n",
    "\n",
    "        assert points.shape[-1] == len(self.src_feature_list)\n",
    "        point_feature_list = [points[:, 0:3]]\n",
    "        for x in self.used_feature_list:\n",
    "            if x in ['x', 'y', 'z']:\n",
    "                continue\n",
    "            idx = self.src_feature_list.index(x)\n",
    "            point_feature_list.append(points[:, idx:idx+1])\n",
    "        point_features = np.concatenate(point_feature_list, axis=1)\n",
    "        \n",
    "        return point_features, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points shape:  (269138, 5)\n",
      "points shape after encoding:  (269138, 5)\n"
     ]
    }
   ],
   "source": [
    "point_feature_encoder = PointFeatureEncoder(\n",
    "    dataset_cfg.POINT_FEATURE_ENCODING,\n",
    "    point_cloud_range=dataset_cfg.POINT_CLOUD_RANGE\n",
    ")\n",
    "num_point_features = point_feature_encoder.num_point_features\n",
    "print(\"points shape: \", points.shape)\n",
    "points, use_lead_xyz = point_feature_encoder.forward(points)\n",
    "print(\"points shape after encoding: \", points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "  def __init__(self, processor_configs, point_cloud_range, training, num_point_features):\n",
    "    self.point_cloud_range = point_cloud_range\n",
    "    self.training = training\n",
    "    self.num_point_features = num_point_features\n",
    "    self.mode = 'train' if training else 'test'\n",
    "    self.grid_size = self.voxel_size = None\n",
    "    self.data_processor_queue = []\n",
    "\n",
    "    self.voxel_generator = None\n",
    "\n",
    "  def mask_points_and_boxes_outside_range(self, points):    \n",
    "    mask = common_utils.mask_points_by_range(points, self.point_cloud_range)\n",
    "    return points[mask]\n",
    "\n",
    "  def shuffle_points(self, points, config=None):\n",
    "    if config.SHUFFLE_ENABLED[self.mode]:\n",
    "        shuffle_idx = np.random.permutation(points.shape[0])\n",
    "        points = points[shuffle_idx]\n",
    "\n",
    "    return points\n",
    "\n",
    "  def double_flip(self, points):\n",
    "    # y flip\n",
    "    points_yflip = points.copy()\n",
    "    points_yflip[:, 1] = -points_yflip[:, 1]\n",
    "\n",
    "    # x flip\n",
    "    points_xflip = points.copy()\n",
    "    points_xflip[:, 0] = -points_xflip[:, 0]\n",
    "\n",
    "    # x y flip\n",
    "    points_xyflip = points.copy()\n",
    "    points_xyflip[:, 0] = -points_xyflip[:, 0]\n",
    "    points_xyflip[:, 1] = -points_xyflip[:, 1]\n",
    "\n",
    "    return points_yflip, points_xflip, points_xyflip\n",
    "\n",
    "  def transform_points_to_voxels(self, points, use_lead_xyz=False, config=None):\n",
    "    if self.voxel_size is None:\n",
    "       self.voxel_size = config.VOXEL_SIZE\n",
    "\n",
    "    if self.grid_size is None:\n",
    "        grid_size = (self.point_cloud_range[3:6] - self.point_cloud_range[0:3]) / np.array(self.voxel_size)\n",
    "        self.grid_size = np.round(grid_size).astype(np.int64)\n",
    "\n",
    "    if self.voxel_generator is None:\n",
    "        self.voxel_generator = VoxelGeneratorWrapper(\n",
    "            vsize_xyz=self.voxel_size,\n",
    "            coors_range_xyz=self.point_cloud_range,\n",
    "            num_point_features=self.num_point_features,\n",
    "            max_num_points_per_voxel=config.MAX_POINTS_PER_VOXEL,\n",
    "            max_num_voxels=config.MAX_NUMBER_OF_VOXELS[self.mode],\n",
    "        )\n",
    "\n",
    "    voxel_output = self.voxel_generator.generate(points)\n",
    "    voxels, coordinates, num_points = voxel_output\n",
    "\n",
    "    if not use_lead_xyz:\n",
    "        voxels = voxels[..., 3:]  # remove xyz in voxels(N, 3)\n",
    "\n",
    "    if config.get('DOUBLE_FLIP', False):\n",
    "        voxels_list, voxel_coords_list, voxel_num_points_list = [voxels], [coordinates], [num_points]\n",
    "        points_yflip, points_xflip, points_xyflip = self.double_flip(points)\n",
    "        points_list = [points_yflip, points_xflip, points_xyflip]\n",
    "        keys = ['yflip', 'xflip', 'xyflip']\n",
    "        for i, key in enumerate(keys):\n",
    "            voxel_output = self.voxel_generator.generate(points_list[i])\n",
    "            voxels, coordinates, num_points = voxel_output\n",
    "\n",
    "            if not use_lead_xyz:\n",
    "                voxels = voxels[..., 3:]\n",
    "            voxels_list.append(voxels)\n",
    "            voxel_coords_list.append(coordinates)\n",
    "            voxel_num_points_list.append(num_points)\n",
    "\n",
    "        return voxels_list, voxel_coords_list, voxel_num_points_list\n",
    "    \n",
    "    return voxels, coordinates, num_points\n",
    "\n",
    "  def sample_points(self, points, config=None):\n",
    "    num_points = config.NUM_POINTS[self.mode]\n",
    "    if num_points == -1:\n",
    "        return points\n",
    "\n",
    "    if num_points < len(points):\n",
    "        pts_depth = np.linalg.norm(points[:, 0:3], axis=1)\n",
    "        pts_near_flag = pts_depth < 40.0\n",
    "        far_idxs_choice = np.where(pts_near_flag == 0)[0]\n",
    "        near_idxs = np.where(pts_near_flag == 1)[0]\n",
    "        choice = []\n",
    "        if num_points > len(far_idxs_choice):\n",
    "            near_idxs_choice = np.random.choice(near_idxs, num_points - len(far_idxs_choice), replace=False)\n",
    "            choice = np.concatenate((near_idxs_choice, far_idxs_choice), axis=0) \\\n",
    "                if len(far_idxs_choice) > 0 else near_idxs_choice\n",
    "        else: \n",
    "            choice = np.arange(0, len(points), dtype=np.int32)\n",
    "            choice = np.random.choice(choice, num_points, replace=False)\n",
    "        np.random.shuffle(choice)\n",
    "    else:\n",
    "        choice = np.arange(0, len(points), dtype=np.int32)\n",
    "        if num_points > len(points):\n",
    "            extra_choice = np.random.choice(choice, num_points - len(points), replace=False)\n",
    "            choice = np.concatenate((choice, extra_choice), axis=0)\n",
    "        np.random.shuffle(choice)\n",
    "    return points[choice]\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud_range = np.array(dataset_cfg.POINT_CLOUD_RANGE, dtype=np.float32)\n",
    "data_p = DataProcessor(dataset_cfg.DATA_PROCESSOR, point_cloud_range, False, num_point_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dp_cfg in dataset_cfg.DATA_PROCESSOR:\n",
    "    if dp_cfg.NAME == 'mask_points_and_boxes_outside_range':\n",
    "        points = data_p.mask_points_and_boxes_outside_range(points)\n",
    "    elif dp_cfg.NAME == 'shuffle_points':\n",
    "        points = data_p.shuffle_points(points, config=dp_cfg)\n",
    "    elif dp_cfg.NAME == 'transform_points_to_voxels':\n",
    "        voxels, coordinates, num_points = data_p.transform_points_to_voxels(points, use_lead_xyz, config=dp_cfg)\n",
    "    else:\n",
    "        raise ValueError('unimplemented processor function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v size:  torch.Size([108911, 10, 5])\n",
      "v num pts:  torch.Size([108911])\n",
      "v coords:  torch.Size([108911, 3])\n"
     ]
    }
   ],
   "source": [
    "# pad coordinates\n",
    "coordinates = np.pad(coordinates, ((0, 0), (1, 0)), mode='constant', constant_values=0)\n",
    "\n",
    "voxels = torch.from_numpy(voxels).float().cuda()\n",
    "coordinates = torch.from_numpy(coordinates).float().cuda()\n",
    "num_points = torch.from_numpy(num_points).float().cuda()\n",
    "\n",
    "print('v size: ', voxels.size())\n",
    "print('v num pts: ', num_points.size())\n",
    "print('v coords: ', coordinates.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mask_points_outside_range(points, point_cloud_range):\n",
    "#   point_cloud_range = np.array(dataset_cfg.POINT_CLOUD_RANGE, dtype=np.float32)\n",
    "#   mask = common_utils.mask_points_by_range(points, point_cloud_range)\n",
    "#   return points[mask]\n",
    "\n",
    "# def shuffle_points(points):\n",
    "#   shuffle_idx = np.random.permutation(points.shape[0])\n",
    "#   return points[shuffle_idx]\n",
    "\n",
    "# points = mask_points_outside_range(points, dataset_cfg.POINT_CLOUD_RANGE)\n",
    "# points = shuffle_points(points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transform points to voxels\n",
    "# voxel_gen_config = next(x for x in dataset_cfg.DATA_PROCESSOR if x.NAME == 'transform_points_to_voxels')\n",
    "# voxel_size = voxel_gen_config.VOXEL_SIZE\n",
    "# point_cloud_range = np.array(dataset_cfg.POINT_CLOUD_RANGE, dtype=np.float32)\n",
    "# grid_size = (point_cloud_range[3:6] - point_cloud_range[0:3]) / np.array(voxel_gen_config.VOXEL_SIZE)\n",
    "\n",
    "# voxel_generator = VoxelGeneratorWrapper(\n",
    "#     vsize_xyz=voxel_size,\n",
    "#     coors_range_xyz=point_cloud_range,\n",
    "#     num_point_features=num_point_features,\n",
    "#     max_num_points_per_voxel=voxel_gen_config.MAX_POINTS_PER_VOXEL,\n",
    "#     max_num_voxels=voxel_gen_config.MAX_NUMBER_OF_VOXELS['test'],\n",
    "# )\n",
    "\n",
    "# voxels, coordinates, num_points = voxel_generator.generate(points)\n",
    "# if not use_lead_xyz:\n",
    "#     voxels = voxels[..., 3:]\n",
    "\n",
    "# voxels = torch.from_numpy(voxels).float().cuda()\n",
    "# coordinates = torch.from_numpy(coordinates).float().cuda()\n",
    "# num_points = torch.from_numpy(num_points).float().cuda()\n",
    "\n",
    "# print('v size: ', voxels.size())\n",
    "# print('v num pts: ', num_points.size())\n",
    "# print('v coords: ', coordinates.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VoxelNext(cfg.MODEL, cfg.CLASS_NAMES, num_point_features,\n",
    "                  data_p.grid_size, point_cloud_range, data_p.voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "spatial shape must equal to ndim",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m      4\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 5\u001b[0m   pred_dicts, ret_dict \u001b[39m=\u001b[39m model(\u001b[39m1\u001b[39;49m, voxels, num_points, coordinates)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/OpenPCDet/tools/nw_models/voxelnext.py:50\u001b[0m, in \u001b[0;36mVoxelNext.forward\u001b[0;34m(self, batch_size, voxels, voxel_num_points, voxel_coords)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, batch_size, voxels, voxel_num_points, voxel_coords):\n\u001b[1;32m     49\u001b[0m   vfe_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvfe(voxels, voxel_num_points)\n\u001b[0;32m---> 50\u001b[0m   encoded_spconv_tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackbone_3d(batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     51\u001b[0m                                            vfe_features\u001b[39m=\u001b[39;49mvfe_features,\n\u001b[1;32m     52\u001b[0m                                            voxel_coords\u001b[39m=\u001b[39;49mvoxel_coords)\n\u001b[1;32m     54\u001b[0m   head_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense_head(batch_size, encoded_spconv_tensor, gt_boxes\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/OpenPCDet/tools/nw_models/modules/spconv_backbone_voxelnext.py:195\u001b[0m, in \u001b[0;36mVoxelResBackBone8xVoxelNeXt.forward\u001b[0;34m(self, batch_size, vfe_features, voxel_coords)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, batch_size, vfe_features, voxel_coords):\n\u001b[1;32m    175\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[39m      batch_size: int\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39m              'x_conv4': 8\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m   input_sp_tensor \u001b[39m=\u001b[39m spconv\u001b[39m.\u001b[39;49mSparseConvTensor(\n\u001b[1;32m    196\u001b[0m       features\u001b[39m=\u001b[39;49mvfe_features,\n\u001b[1;32m    197\u001b[0m       indices\u001b[39m=\u001b[39;49mvoxel_coords\u001b[39m.\u001b[39;49mint(),\n\u001b[1;32m    198\u001b[0m       spatial_shape\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse_shape,\n\u001b[1;32m    199\u001b[0m       batch_size\u001b[39m=\u001b[39;49mbatch_size\n\u001b[1;32m    200\u001b[0m   )\n\u001b[1;32m    201\u001b[0m   x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_input(input_sp_tensor)\n\u001b[1;32m    203\u001b[0m   \u001b[39m# TODO: remove intermediates\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/fx/_symbolic_trace.py:92\u001b[0m, in \u001b[0;36mProxyableClassMeta.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[39mreturn\u001b[39;00m tracer\u001b[39m.\u001b[39mcreate_proxy(\u001b[39m'\u001b[39m\u001b[39mcall_function\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mcls\u001b[39m, args, kwargs)\n\u001b[1;32m     91\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(instance, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[39mreturn\u001b[39;00m instance\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/spconv/pytorch/core.py:162\u001b[0m, in \u001b[0;36mSparseConvTensor.__init__\u001b[0;34m(self, features, indices, spatial_shape, batch_size, grid, voxel_num, indice_dict, benchmark, permanent_thrust_allocator, enable_timer, force_algo)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39massert\u001b[39;00m features\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    161\u001b[0m \u001b[39massert\u001b[39;00m indices\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m--> 162\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(spatial_shape) \u001b[39m==\u001b[39m ndim, \u001b[39m\"\u001b[39m\u001b[39mspatial shape must equal to ndim\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m \u001b[39massert\u001b[39;00m indices\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mint32, \u001b[39m\"\u001b[39m\u001b[39monly support int32\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m \u001b[39massert\u001b[39;00m batch_size \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: spatial shape must equal to ndim"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "  pred_dicts, ret_dict = model(1, voxels, num_points, coordinates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
