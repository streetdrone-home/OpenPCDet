{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from pcdet.config import cfg, cfg_from_list, cfg_from_yaml_file, log_config_to_file\n",
    "from pcdet.utils import common_utils\n",
    "import torch\n",
    "import datetime\n",
    "\n",
    "tv = None\n",
    "try:\n",
    "  import cumm.tensorview as tv\n",
    "except:\n",
    "  pass\n",
    "\n",
    "from nw_models.voxelnext import VoxelNext\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = Path(\"/home/cuda_pp/OpenPCDet/data/nuscenes/v1.0-mini\")\n",
    "\n",
    "info_path = Path(\"/home/cuda_pp/OpenPCDet/data/nuscenes/v1.0-mini/nuscenes_infos_10sweeps_val.pkl\")\n",
    "\n",
    "with open(info_path, 'rb') as f:\n",
    "  infos = pickle.load(f)\n",
    "  info = infos[3]\n",
    "  # pprint(infos[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ego_points(points, center_radius=1.0):\n",
    "  mask = ~((np.abs(points[:, 0]) < center_radius) & (np.abs(points[:, 1]) < center_radius))\n",
    "  return points[mask]\n",
    "\n",
    "def get_sweep(sweep_info):\n",
    "    lidar_path = root_path / sweep_info['lidar_path']\n",
    "    points_sweep = np.fromfile(str(lidar_path), dtype=np.float32, count=-1).reshape([-1, 5])[:, :4]\n",
    "    points_sweep = remove_ego_points(points_sweep).T\n",
    "    if sweep_info['transform_matrix'] is not None:\n",
    "        num_points = points_sweep.shape[1]\n",
    "        points_sweep[:3, :] = sweep_info['transform_matrix'].dot(\n",
    "            np.vstack((points_sweep[:3, :], np.ones(num_points))))[:3, :]\n",
    "\n",
    "    cur_times = sweep_info['time_lag'] * np.ones((1, points_sweep.shape[1]))\n",
    "    return points_sweep.T, cur_times.T\n",
    "\n",
    "def get_lidar_with_sweeps(info, max_sweeps=1):\n",
    "    lidar_path = root_path / info['lidar_path']\n",
    "    points = np.fromfile(str(lidar_path), dtype=np.float32, count=-1).reshape([-1, 5])[:, :4]\n",
    "\n",
    "    sweep_points_list = [points]\n",
    "    sweep_times_list = [np.zeros((points.shape[0], 1))]\n",
    "\n",
    "    for k in np.random.choice(len(info['sweeps']), max_sweeps - 1, replace=False):\n",
    "        points_sweep, times_sweep = get_sweep(info['sweeps'][k])\n",
    "        sweep_points_list.append(points_sweep)\n",
    "        sweep_times_list.append(times_sweep)\n",
    "\n",
    "    points = np.concatenate(sweep_points_list, axis=0)\n",
    "    times = np.concatenate(sweep_times_list, axis=0).astype(points.dtype)\n",
    "\n",
    "    points = np.concatenate((points, times), axis=1)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# DATASET CONFIG ###################\n",
      " {'DATASET': 'NuScenesDataset', 'DATA_PATH': '../data/nuscenes', 'VERSION': 'v1.0-mini', 'MAX_SWEEPS': 10, 'PRED_VELOCITY': True, 'SET_NAN_VELOCITY_TO_ZEROS': True, 'FILTER_MIN_POINTS_IN_GT': 1, 'DATA_SPLIT': {'train': 'train', 'test': 'val'}, 'INFO_PATH': {'train': ['nuscenes_infos_10sweeps_train.pkl'], 'test': ['nuscenes_infos_10sweeps_val.pkl']}, 'POINT_CLOUD_RANGE': [-54.0, -54.0, -5.0, 54.0, 54.0, 3.0], 'BALANCED_RESAMPLING': True, 'DATA_AUGMENTOR': {'DISABLE_AUG_LIST': ['placeholder'], 'AUG_CONFIG_LIST': [{'NAME': 'gt_sampling', 'DB_INFO_PATH': ['nuscenes_dbinfos_10sweeps_withvelo.pkl'], 'USE_SHARED_MEMORY': False, 'DB_DATA_PATH': ['nuscenes_dbinfos_10sweeps_withvelo_global.pkl.npy'], 'PREPARE': {'filter_by_min_points': ['car:5', 'truck:5', 'construction_vehicle:5', 'bus:5', 'trailer:5', 'barrier:5', 'motorcycle:5', 'bicycle:5', 'pedestrian:5', 'traffic_cone:5']}, 'SAMPLE_GROUPS': ['car:2', 'truck:2', 'construction_vehicle:2', 'bus:2', 'trailer:2', 'barrier:2', 'motorcycle:2', 'bicycle:2', 'pedestrian:2', 'traffic_cone:2'], 'NUM_POINT_FEATURES': 5, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': True}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x', 'y']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.9, 1.1]}, {'NAME': 'random_world_translation', 'NOISE_TRANSLATE_STD': [0.5, 0.5, 0.5]}]}, 'POINT_FEATURE_ENCODING': {'encoding_type': 'absolute_coordinates_encoding', 'used_feature_list': ['x', 'y', 'z', 'intensity', 'timestamp'], 'src_feature_list': ['x', 'y', 'z', 'intensity', 'timestamp']}, 'DATA_PROCESSOR': [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': True}}, {'NAME': 'transform_points_to_voxels', 'VOXEL_SIZE': [0.075, 0.075, 0.2], 'MAX_POINTS_PER_VOXEL': 10, 'MAX_NUMBER_OF_VOXELS': {'train': 120000, 'test': 160000}}], '_BASE_CONFIG_': 'cfgs/dataset_configs/nuscenes_dataset.yaml'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cfg_file = \"/home/cuda_pp/OpenPCDet/tools/cfgs/nuscenes_models/cbgs_voxel0075_voxelnext.yaml\"\n",
    "\n",
    "cfg_from_yaml_file(cfg_file, cfg)\n",
    "cfg.TAG = Path(cfg_file).stem\n",
    "cfg.EXP_GROUP_PATH = '/'.join(cfg_file.split('/')[1:-1])  # remove 'cfgs' and 'xxxx.yaml'\n",
    "\n",
    "dataset_cfg = cfg.DATA_CONFIG\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "print(\"############# DATASET CONFIG ###################\\n\", dataset_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = get_lidar_with_sweeps(info, max_sweeps=dataset_cfg.MAX_SWEEPS)\n",
    "# orig_points = points.copy()\n",
    "np.save('points.npy', points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle point indexes\n",
    "# shuffle_idx = np.random.permutation(points.shape[0])\n",
    "# points = points[shuffle_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoxelGeneratorWrapper():\n",
    "  def __init__(\n",
    "          self, vsize_xyz, coors_range_xyz, num_point_features, max_num_points_per_voxel,\n",
    "          max_num_voxels):\n",
    "    try:\n",
    "      from spconv.utils import VoxelGeneratorV2 as VoxelGenerator\n",
    "      self.spconv_ver = 1\n",
    "    except:\n",
    "      try:\n",
    "        from spconv.utils import VoxelGenerator\n",
    "        self.spconv_ver = 1\n",
    "      except:\n",
    "        from spconv.utils import Point2VoxelCPU3d as VoxelGenerator\n",
    "        self.spconv_ver = 2\n",
    "\n",
    "    if self.spconv_ver == 1:\n",
    "      self._voxel_generator = VoxelGenerator(\n",
    "          voxel_size=vsize_xyz,\n",
    "          point_cloud_range=coors_range_xyz,\n",
    "          max_num_points=max_num_points_per_voxel,\n",
    "          max_voxels=max_num_voxels\n",
    "      )\n",
    "    else:\n",
    "      self._voxel_generator = VoxelGenerator(\n",
    "          vsize_xyz=vsize_xyz,\n",
    "          coors_range_xyz=coors_range_xyz,\n",
    "          num_point_features=num_point_features,\n",
    "          max_num_points_per_voxel=max_num_points_per_voxel,\n",
    "          max_num_voxels=max_num_voxels\n",
    "      )\n",
    "\n",
    "  def generate(self, points):\n",
    "    if self.spconv_ver == 1:\n",
    "      voxel_output = self._voxel_generator.generate(points)\n",
    "      if isinstance(voxel_output, dict):\n",
    "        voxels, coordinates, num_points = \\\n",
    "            voxel_output['voxels'], voxel_output['coordinates'], voxel_output['num_points_per_voxel']\n",
    "      else:\n",
    "        voxels, coordinates, num_points = voxel_output\n",
    "    else:\n",
    "      assert tv is not None, f\"Unexpected error, library: 'cumm' wasn't imported properly.\"\n",
    "      voxel_output = self._voxel_generator.point_to_voxel(tv.from_numpy(points))\n",
    "      tv_voxels, tv_coordinates, tv_num_points = voxel_output\n",
    "      # make copy with numpy(), since numpy_view() will disappear as soon as the generator is deleted\n",
    "      voxels = tv_voxels.numpy()\n",
    "      coordinates = tv_coordinates.numpy()\n",
    "      num_points = tv_num_points.numpy()\n",
    "    return voxels, coordinates, num_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointFeatureEncoder(object):\n",
    "    def __init__(self, config, point_cloud_range=None):\n",
    "        super().__init__()\n",
    "        self.point_encoding_config = config\n",
    "        assert list(self.point_encoding_config.src_feature_list[0:3]) == ['x', 'y', 'z']\n",
    "        self.used_feature_list = self.point_encoding_config.used_feature_list\n",
    "        self.src_feature_list = self.point_encoding_config.src_feature_list\n",
    "        self.point_cloud_range = point_cloud_range\n",
    "\n",
    "    @property\n",
    "    def num_point_features(self):\n",
    "        return getattr(self, self.point_encoding_config.encoding_type)(points=None)\n",
    "\n",
    "    def forward(self, points):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dict:\n",
    "                points: (N, 3 + C_in)\n",
    "                ...\n",
    "        Returns:\n",
    "            data_dict:\n",
    "                points: (N, 3 + C_out),\n",
    "                use_lead_xyz: whether to use xyz as point-wise features\n",
    "                ...\n",
    "        \"\"\"\n",
    "        points, use_lead_xyz = getattr(self, self.point_encoding_config.encoding_type)(\n",
    "            points\n",
    "        )\n",
    "       \n",
    "        if self.point_encoding_config.get('filter_sweeps', False) and 'timestamp' in self.src_feature_list:\n",
    "            max_sweeps = self.point_encoding_config.max_sweeps\n",
    "            idx = self.src_feature_list.index('timestamp')\n",
    "            dt = np.round(points[:, idx], 2)\n",
    "            max_dt = sorted(np.unique(dt))[min(len(np.unique(dt))-1, max_sweeps-1)]\n",
    "            points = points[dt <= max_dt]\n",
    "        \n",
    "        return points, use_lead_xyz\n",
    "\n",
    "    def absolute_coordinates_encoding(self, points=None):\n",
    "        if points is None:\n",
    "            num_output_features = len(self.used_feature_list)\n",
    "            return num_output_features\n",
    "\n",
    "        assert points.shape[-1] == len(self.src_feature_list)\n",
    "        point_feature_list = [points[:, 0:3]]\n",
    "        for x in self.used_feature_list:\n",
    "            if x in ['x', 'y', 'z']:\n",
    "                continue\n",
    "            idx = self.src_feature_list.index(x)\n",
    "            point_feature_list.append(points[:, idx:idx+1])\n",
    "        point_features = np.concatenate(point_feature_list, axis=1)\n",
    "        \n",
    "        return point_features, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points shape:  (227340, 5)\n",
      "points shape after encoding:  (227340, 5)\n"
     ]
    }
   ],
   "source": [
    "point_feature_encoder = PointFeatureEncoder(\n",
    "    dataset_cfg.POINT_FEATURE_ENCODING,\n",
    "    point_cloud_range=dataset_cfg.POINT_CLOUD_RANGE\n",
    ")\n",
    "num_point_features = point_feature_encoder.num_point_features\n",
    "print(\"points shape: \", points.shape)\n",
    "points, use_lead_xyz = point_feature_encoder.forward(points)\n",
    "print(\"points shape after encoding: \", points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "  def __init__(self, processor_configs, point_cloud_range, training, num_point_features):\n",
    "    self.point_cloud_range = point_cloud_range\n",
    "    self.training = training\n",
    "    self.num_point_features = num_point_features\n",
    "    self.mode = 'train' if training else 'test'\n",
    "    self.grid_size = self.voxel_size = None\n",
    "    self.data_processor_queue = []\n",
    "\n",
    "    self.voxel_generator = None\n",
    "\n",
    "  def mask_points_and_boxes_outside_range(self, points):    \n",
    "    mask = common_utils.mask_points_by_range(points, self.point_cloud_range)\n",
    "    return points[mask]\n",
    "\n",
    "  def shuffle_points(self, points, config=None):\n",
    "    if config.SHUFFLE_ENABLED[self.mode]:\n",
    "        shuffle_idx = np.random.permutation(points.shape[0])\n",
    "        points = points[shuffle_idx]\n",
    "\n",
    "    return points\n",
    "\n",
    "  def double_flip(self, points):\n",
    "    # y flip\n",
    "    points_yflip = points.copy()\n",
    "    points_yflip[:, 1] = -points_yflip[:, 1]\n",
    "\n",
    "    # x flip\n",
    "    points_xflip = points.copy()\n",
    "    points_xflip[:, 0] = -points_xflip[:, 0]\n",
    "\n",
    "    # x y flip\n",
    "    points_xyflip = points.copy()\n",
    "    points_xyflip[:, 0] = -points_xyflip[:, 0]\n",
    "    points_xyflip[:, 1] = -points_xyflip[:, 1]\n",
    "\n",
    "    return points_yflip, points_xflip, points_xyflip\n",
    "\n",
    "  def transform_points_to_voxels(self, points, use_lead_xyz=False, config=None):\n",
    "    if self.voxel_size is None:\n",
    "       self.voxel_size = config.VOXEL_SIZE\n",
    "\n",
    "    if self.grid_size is None:\n",
    "        grid_size = (self.point_cloud_range[3:6] - self.point_cloud_range[0:3]) / np.array(self.voxel_size)\n",
    "        self.grid_size = np.round(grid_size).astype(np.int64)\n",
    "\n",
    "    if self.voxel_generator is None:\n",
    "        self.voxel_generator = VoxelGeneratorWrapper(\n",
    "            vsize_xyz=self.voxel_size,\n",
    "            coors_range_xyz=self.point_cloud_range,\n",
    "            num_point_features=self.num_point_features,\n",
    "            max_num_points_per_voxel=config.MAX_POINTS_PER_VOXEL,\n",
    "            max_num_voxels=config.MAX_NUMBER_OF_VOXELS[self.mode],\n",
    "        )\n",
    "\n",
    "    voxel_output = self.voxel_generator.generate(points)\n",
    "    voxels, coordinates, num_points = voxel_output\n",
    "\n",
    "    if not use_lead_xyz:\n",
    "        voxels = voxels[..., 3:]  # remove xyz in voxels(N, 3)\n",
    "\n",
    "    if config.get('DOUBLE_FLIP', False):\n",
    "        voxels_list, voxel_coords_list, voxel_num_points_list = [voxels], [coordinates], [num_points]\n",
    "        points_yflip, points_xflip, points_xyflip = self.double_flip(points)\n",
    "        points_list = [points_yflip, points_xflip, points_xyflip]\n",
    "        keys = ['yflip', 'xflip', 'xyflip']\n",
    "        for i, key in enumerate(keys):\n",
    "            voxel_output = self.voxel_generator.generate(points_list[i])\n",
    "            voxels, coordinates, num_points = voxel_output\n",
    "\n",
    "            if not use_lead_xyz:\n",
    "                voxels = voxels[..., 3:]\n",
    "            voxels_list.append(voxels)\n",
    "            voxel_coords_list.append(coordinates)\n",
    "            voxel_num_points_list.append(num_points)\n",
    "\n",
    "        return voxels_list, voxel_coords_list, voxel_num_points_list\n",
    "    \n",
    "    return voxels, coordinates, num_points\n",
    "\n",
    "  def sample_points(self, points, config=None):\n",
    "    num_points = config.NUM_POINTS[self.mode]\n",
    "    if num_points == -1:\n",
    "        return points\n",
    "\n",
    "    if num_points < len(points):\n",
    "        pts_depth = np.linalg.norm(points[:, 0:3], axis=1)\n",
    "        pts_near_flag = pts_depth < 40.0\n",
    "        far_idxs_choice = np.where(pts_near_flag == 0)[0]\n",
    "        near_idxs = np.where(pts_near_flag == 1)[0]\n",
    "        choice = []\n",
    "        if num_points > len(far_idxs_choice):\n",
    "            near_idxs_choice = np.random.choice(near_idxs, num_points - len(far_idxs_choice), replace=False)\n",
    "            choice = np.concatenate((near_idxs_choice, far_idxs_choice), axis=0) \\\n",
    "                if len(far_idxs_choice) > 0 else near_idxs_choice\n",
    "        else: \n",
    "            choice = np.arange(0, len(points), dtype=np.int32)\n",
    "            choice = np.random.choice(choice, num_points, replace=False)\n",
    "        np.random.shuffle(choice)\n",
    "    else:\n",
    "        choice = np.arange(0, len(points), dtype=np.int32)\n",
    "        if num_points > len(points):\n",
    "            extra_choice = np.random.choice(choice, num_points - len(points), replace=False)\n",
    "            choice = np.concatenate((choice, extra_choice), axis=0)\n",
    "        np.random.shuffle(choice)\n",
    "    return points[choice]\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud_range = np.array(dataset_cfg.POINT_CLOUD_RANGE, dtype=np.float32)\n",
    "data_p = DataProcessor(dataset_cfg.DATA_PROCESSOR, point_cloud_range, False, num_point_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dp_cfg in dataset_cfg.DATA_PROCESSOR:\n",
    "    if dp_cfg.NAME == 'mask_points_and_boxes_outside_range':\n",
    "        points = data_p.mask_points_and_boxes_outside_range(points)\n",
    "    elif dp_cfg.NAME == 'shuffle_points':\n",
    "        points = data_p.shuffle_points(points, config=dp_cfg)\n",
    "    elif dp_cfg.NAME == 'transform_points_to_voxels':\n",
    "        voxels, coordinates, num_points = data_p.transform_points_to_voxels(points, use_lead_xyz, config=dp_cfg)\n",
    "    else:\n",
    "        raise ValueError('unimplemented processor function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v size:  torch.Size([84717, 10, 5])\n",
      "v num pts:  torch.Size([84717])\n",
      "v coords:  torch.Size([84717, 4])\n"
     ]
    }
   ],
   "source": [
    "# pad coordinates for single inference\n",
    "coordinates = np.pad(coordinates, ((0, 0), (1, 0)), mode='constant', constant_values=0)\n",
    "\n",
    "# voxels = np.concatenate((voxels, voxels, voxels, voxels), axis=0)\n",
    "# num_points = np.concatenate((num_points, num_points, num_points, num_points), axis=0)\n",
    "# coordinates = np.concatenate((\n",
    "#   np.pad(coordinates, ((0, 0), (1, 0)), mode='constant', constant_values=0),\n",
    "#   np.pad(coordinates, ((0, 0), (1, 0)), mode='constant', constant_values=1),\n",
    "#   np.pad(coordinates, ((0, 0), (1, 0)), mode='constant', constant_values=2),\n",
    "#   np.pad(coordinates, ((0, 0), (1, 0)), mode='constant', constant_values=3)\n",
    "# ), axis=0)\n",
    "\n",
    "\n",
    "voxels = torch.from_numpy(voxels).float().cuda()\n",
    "coordinates = torch.from_numpy(coordinates).float().cuda()\n",
    "num_points = torch.from_numpy(num_points).float().cuda()\n",
    "\n",
    "print('v size: ', voxels.size())\n",
    "print('v num pts: ', num_points.size())\n",
    "print('v coords: ', coordinates.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mask_points_outside_range(points, point_cloud_range):\n",
    "#   point_cloud_range = np.array(dataset_cfg.POINT_CLOUD_RANGE, dtype=np.float32)\n",
    "#   mask = common_utils.mask_points_by_range(points, point_cloud_range)\n",
    "#   return points[mask]\n",
    "\n",
    "# def shuffle_points(points):\n",
    "#   shuffle_idx = np.random.permutation(points.shape[0])\n",
    "#   return points[shuffle_idx]\n",
    "\n",
    "# points = mask_points_outside_range(points, dataset_cfg.POINT_CLOUD_RANGE)\n",
    "# points = shuffle_points(points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transform points to voxels\n",
    "# voxel_gen_config = next(x for x in dataset_cfg.DATA_PROCESSOR if x.NAME == 'transform_points_to_voxels')\n",
    "# voxel_size = voxel_gen_config.VOXEL_SIZE\n",
    "# point_cloud_range = np.array(dataset_cfg.POINT_CLOUD_RANGE, dtype=np.float32)\n",
    "# grid_size = (point_cloud_range[3:6] - point_cloud_range[0:3]) / np.array(voxel_gen_config.VOXEL_SIZE)\n",
    "\n",
    "# voxel_generator = VoxelGeneratorWrapper(\n",
    "#     vsize_xyz=voxel_size,\n",
    "#     coors_range_xyz=point_cloud_range,\n",
    "#     num_point_features=num_point_features,\n",
    "#     max_num_points_per_voxel=voxel_gen_config.MAX_POINTS_PER_VOXEL,\n",
    "#     max_num_voxels=voxel_gen_config.MAX_NUMBER_OF_VOXELS['test'],\n",
    "# )\n",
    "\n",
    "# voxels, coordinates, num_points = voxel_generator.generate(points)\n",
    "# if not use_lead_xyz:\n",
    "#     voxels = voxels[..., 3:]\n",
    "\n",
    "# voxels = torch.from_numpy(voxels).float().cuda()\n",
    "# coordinates = torch.from_numpy(coordinates).float().cuda()\n",
    "# num_points = torch.from_numpy(num_points).float().cuda()\n",
    "\n",
    "# print('v size: ', voxels.size())\n",
    "# print('v num pts: ', num_points.size())\n",
    "# print('v coords: ', coordinates.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VoxelNext(cfg.MODEL, cfg.CLASS_NAMES, num_point_features,\n",
    "                  data_p.grid_size, point_cloud_range, data_p.voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-09 15:01:12,375   INFO  ==> Loading parameters from checkpoint /home/cuda_pp/OpenPCDet/ckpts/voxelnext_nuscenes_kernel1.pth to GPU\n",
      "2023-08-09 15:01:12,375   INFO  ==> Loading parameters from checkpoint /home/cuda_pp/OpenPCDet/ckpts/voxelnext_nuscenes_kernel1.pth to GPU\n",
      "2023-08-09 15:01:12,431   INFO  ==> Done (loaded 542/542)\n",
      "2023-08-09 15:01:12,431   INFO  ==> Done (loaded 542/542)\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = \"/home/cuda_pp/OpenPCDet/ckpts/voxelnext_nuscenes_kernel1.pth\"\n",
    "log_file = ('log_test_%s.txt' % datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "logger = common_utils.create_logger(log_file=log_file)\n",
    "model.load_params_from_file(filename=model_ckpt, logger=logger)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "  pred_dicts, ret_dict = model(batch_size, voxels, num_points, coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'pred_boxes': tensor([[ 9.7161e-01, -1.9272e+01, -2.1580e+00,  ...,  1.6900e+00,\n",
      "         -8.3213e-01,  8.3179e+00],\n",
      "        [ 1.3535e-01, -5.2537e+01, -3.6269e+00,  ..., -1.5304e+00,\n",
      "          3.8037e-01, -1.1829e+01],\n",
      "        [ 5.4077e+00,  4.0326e+01,  1.2593e+00,  ...,  1.4179e+00,\n",
      "          1.1147e+00,  7.5676e+00],\n",
      "        ...,\n",
      "        [-1.7301e+01,  1.5410e+01, -1.0835e+00,  ..., -2.3259e+00,\n",
      "          9.1271e-05, -7.7826e-04],\n",
      "        [ 1.1913e+01,  2.7659e+01,  5.4830e-01,  ..., -3.3023e-01,\n",
      "          2.1559e-01, -2.1630e-02],\n",
      "        [ 1.0168e+01,  2.5379e+01,  2.8453e-01,  ..., -1.9321e+00,\n",
      "         -4.1692e-01, -1.0746e+00]], device='cuda:0'),\n",
      "  'pred_ious': [None, None, None, None, None, None],\n",
      "  'pred_labels': tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  3,  2,  3,  2,\n",
      "         2,  2,  3,  4,  4,  5,  4,  5,  6,  6,  6,  6,  6,  7,  8,  8,  7,  8,\n",
      "         8,  7,  8,  8,  8,  7,  7,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10,  9,  9,\n",
      "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "         9,  9,  9,  9,  9, 10,  9,  9,  9,  9, 10,  9, 10,  9,  9,  9,  9,  9,\n",
      "         9,  9,  9,  9,  9, 10,  9,  9,  9,  9, 10,  9,  9,  9,  9,  9,  9,  9],\n",
      "       device='cuda:0'),\n",
      "  'pred_scores': tensor([0.8222, 0.7472, 0.7438, 0.7103, 0.5738, 0.5665, 0.4389, 0.1667, 0.1642,\n",
      "        0.1505, 0.1483, 0.1289, 0.1265, 0.1238, 0.3646, 0.3584, 0.2138, 0.1614,\n",
      "        0.1314, 0.1101, 0.1015, 0.3299, 0.2825, 0.2664, 0.1201, 0.1151, 0.1379,\n",
      "        0.1299, 0.1255, 0.1150, 0.1026, 0.2404, 0.2089, 0.1774, 0.1712, 0.1569,\n",
      "        0.1314, 0.1183, 0.1135, 0.1106, 0.1099, 0.1060, 0.1022, 0.9148, 0.9147,\n",
      "        0.9111, 0.8845, 0.8757, 0.8315, 0.7903, 0.7774, 0.7670, 0.7661, 0.7443,\n",
      "        0.7433, 0.7431, 0.7309, 0.7257, 0.7215, 0.7084, 0.7047, 0.6974, 0.6924,\n",
      "        0.6879, 0.6658, 0.6602, 0.6584, 0.6579, 0.6354, 0.6270, 0.5953, 0.5910,\n",
      "        0.5844, 0.5791, 0.5772, 0.5578, 0.5541, 0.5275, 0.5045, 0.5015, 0.4918,\n",
      "        0.4837, 0.4788, 0.4669, 0.4566, 0.4418, 0.4189, 0.4159, 0.4140, 0.4118,\n",
      "        0.4097, 0.4091, 0.4082, 0.3949, 0.3790, 0.3747, 0.3708, 0.3592, 0.3100,\n",
      "        0.3042, 0.3013, 0.2985, 0.2938, 0.2913, 0.2562, 0.2550, 0.2533, 0.2470,\n",
      "        0.2467, 0.2446, 0.2357, 0.2319, 0.2318, 0.2308, 0.2214, 0.2199, 0.2184,\n",
      "        0.2172, 0.2130, 0.2127, 0.1993, 0.1953, 0.1952, 0.1950, 0.1946, 0.1897],\n",
      "       device='cuda:0')}]\n"
     ]
    }
   ],
   "source": [
    "pprint(pred_dicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.77194941e+00 -8.73386383e+00 -2.35381866e+00  1.20000000e+01\n",
      "   3.99771929e-01]\n",
      " [-1.94788468e-03 -1.61905065e-01 -1.24468626e-02  3.00000000e+01\n",
      "   0.00000000e+00]\n",
      " [ 3.65204024e+00 -4.80554676e+00 -2.17789435e+00  4.00000000e+00\n",
      "   4.50101852e-01]\n",
      " ...\n",
      " [-7.58547688e+00 -3.25902843e+00 -2.26735449e+00  1.40000000e+01\n",
      "   3.99771929e-01]\n",
      " [-3.64270711e+00  4.55621529e+00 -1.74788022e+00  5.00000000e+00\n",
      "   4.97629642e-02]\n",
      " [-8.03525066e+00 -1.31858015e+01 -2.15981221e+00  1.80000000e+01\n",
      "   4.50101852e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('points.npy', orig_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_boxes\n",
      "<class 'torch.Tensor'>\n",
      "pred_scores\n",
      "<class 'torch.Tensor'>\n",
      "pred_labels\n",
      "<class 'torch.Tensor'>\n",
      "pred_ious\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "out_dict = {}\n",
    "for key, value in pred_dicts[0].items():\n",
    "    print(key)\n",
    "    print(type(value))\n",
    "    if not isinstance(value, list):\n",
    "        out_dict[key] = value.cpu()\n",
    "\n",
    "torch.save(out_dict, 'pred_dicts1.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
